{
  "success": true,
  "project_metadata": {
    "version": "0.1.0",
    "author": "Your Name",
    "description": "Automated README generation for Python projects using LLM APIs",
    "email": "your.email@example.com",
    "name": "src"
  },
  "dependencies": [],
  "entry_points": {
    "main_modules": [
      {
        "type": "main_module",
        "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\__main__.py",
        "usage": "python -m src",
        "source_code": "\"\"\"\nCLI entry point for the README generator package.\n\nThis module provides the main entry point when the package is run as a module\nusing 'python -m readme_generator'. It handles command-line argument parsing\nand delegates to the appropriate CLI functions.\n\"\"\"\n\nimport sys\nimport os\nimport logging\nfrom pathlib import Path\n\n# Add the package to Python path if running as script\nif __name__ == \"__main__\":\n    # Get the directory containing this file\n    current_dir = Path(__file__).parent\n    # Add parent directory to path so we can import the package\n    sys.path.insert(0, str(current_dir.parent))\n\nfrom cli import main\n\n\ndef setup_logging(verbose: bool = False):\n    \"\"\"Set up logging configuration.\"\"\"\n    log_level = logging.DEBUG if verbose else logging.INFO\n    \n    # Create formatter\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n    )\n    \n    # Set up console handler\n    console_handler = logging.StreamHandler(sys.stdout)\n    console_handler.setFormatter(formatter)\n    \n    # Configure root logger\n    root_logger = logging.getLogger()\n    root_logger.setLevel(log_level)\n    root_logger.addHandler(console_handler)\n    \n    # Reduce noise from third-party libraries\n    logging.getLogger('urllib3').setLevel(logging.WARNING)\n    logging.getLogger('requests').setLevel(logging.WARNING)\n    logging.getLogger('httpx').setLevel(logging.WARNING)\n\n\ndef check_python_version():\n    \"\"\"Check if Python version is compatible.\"\"\"\n    if sys.version_info < (3, 8):\n        print(\"Error: Python 3.8 or higher is required.\")\n        print(f\"You are using Python {sys.version}\")\n        sys.exit(1)\n\n\ndef handle_exceptions():\n    \"\"\"Set up global exception handling.\"\"\"\n    def exception_handler(exc_type, exc_value, exc_traceback):\n        if issubclass(exc_type, KeyboardInterrupt):\n            print(\"\\nOperation cancelled by user.\")\n            sys.exit(1)\n        else:\n            # Log the exception\n            logging.error(\n                \"Uncaught exception\", \n                exc_info=(exc_type, exc_value, exc_traceback)\n            )\n            print(f\"An unexpected error occurred: {exc_value}\")\n            sys.exit(1)\n    \n    sys.excepthook = exception_handler\n\n\ndef entry_point():\n    \"\"\"Main entry point for the CLI application.\"\"\"\n    try:\n        # Check Python version compatibility\n        check_python_version()\n        \n        # Set up global exception handling\n        handle_exceptions()\n        \n        # Parse arguments and determine verbosity early\n        verbose = '--verbose' in sys.argv or '-v' in sys.argv\n        \n        # Set up logging\n        setup_logging(verbose)\n        \n        # Log startup information\n        logger = logging.getLogger(__name__)\n        logger.info(f\"Starting README Generator v{get_version()}\")\n        logger.debug(f\"Python version: {sys.version}\")\n        logger.debug(f\"Command line arguments: {sys.argv}\")\n        \n        # Run the main CLI function\n        main()\n        \n    except Exception as e:\n        print(f\"Failed to start README Generator: {e}\")\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    # Import version info\n    try:\n        from readme_generator import get_version\n    except ImportError:\n        def get_version():\n            return \"0.1.0\"\n    \n    entry_point()\n",
        "docstring": "CLI entry point for the README generator package.\n\nThis module provides the main entry point when the package is run as a module\nusing 'python -m readme_generator'. It handles command-line argument parsing\nand delegates to the appropriate CLI functions.",
        "description": "Main module entry point"
      }
    ],
    "cli_scripts": [
      {
        "type": "cli_script",
        "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\cli.py",
        "usage": "python cli.py",
        "source_code": "\"\"\"\nCommand-line interface for the README generator.\n\nThis module provides the main CLI functionality for automatically generating\ncomprehensive README files for Python projects using LLM APIs,\noptimized for Gemini 2.5 Pro with a 1M token window.\n\"\"\"\n\nimport os\nimport sys\nimport argparse\nimport time\nimport json\nimport asyncio\nfrom pathlib import Path\nimport logging\n\n# Optional: Third-party LLM APIs\ntry:\n    import google.generativeai as genai\nexcept ImportError:\n    genai = None\n\ntry:\n    import openai\nexcept ImportError:\n    openai = None\n\ntry:\n    import anthropic\nexcept ImportError:\n    anthropic = None\n\nfrom config import Config, load_config, save_config\nfrom parser.project_parser import parse_project\nfrom utils.token_counter import estimate_tokens\nfrom utils.file_utils import create_directory\nfrom utils.json_serializer import serialize_project_data, save_json_to_file\n\nlogger = logging.getLogger(__name__)\n\nclass CLIError(Exception):\n    pass\n\nclass LLMAPIError(Exception):\n    pass\n\ndef create_parser() -> argparse.ArgumentParser:\n    parser = argparse.ArgumentParser(\n        prog=\"readme-generator\",\n        description=\"Generate a README for a Python project using LLMs.\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        epilog=\"\"\"\nExamples:\n  readme-generator /path/to/project\n  readme-generator . --output custom_readme.md\n  readme-generator /path/to/project --model gemini_2_5_pro\n  readme-generator /path/to/project --api-key YOUR_API_KEY\n  readme-generator --init-config\n\nPerformance Target:\n  Generates README for projects up to 25 files/5,000 lines in under 90 seconds\n        \"\"\"\n    )\n    parser.add_argument('--version', action='version', version='%(prog)s 1.0')\n    parser.add_argument('--parse-only', action='store_true', help='Only parse project data to JSON, skip README generation')\n    parser.add_argument('project_path', nargs='?', help='Path to the Python project root directory')\n    parser.add_argument('--output', '-o', type=str, default='README.md', help='Output README file path')\n    parser.add_argument('--json-output', type=str, help='Save parsed project data as JSON file')\n    parser.add_argument('--model', choices=['gemini_2_5_pro', 'gemini_2_5_flash', 'gpt_4o', 'gpt_4o_mini', 'claude_sonnet'], default='gemini_2_5_pro', help='LLM model to use')\n    parser.add_argument('--api-key', type=str, help='API key for LLM service')\n    parser.add_argument('--max-tokens', type=int, default=1_000_000, help='Maximum token budget')\n    parser.add_argument('--include-tests', action='store_true', help='Include test files in analysis')\n    parser.add_argument('--include-private', action='store_true', help='Include private methods and classes')\n    parser.add_argument('--config', type=str, help='Path to configuration file')\n    parser.add_argument('--init-config', action='store_true', help='Initialize configuration file with default settings')\n    parser.add_argument('--save-config', type=str, help='Save current settings to configuration file')\n    parser.add_argument('--verbose', '-v', action='store_true', help='Enable verbose output')\n    parser.add_argument('--quiet', '-q', action='store_true', help='Suppress non-error output')\n    parser.add_argument('--debug', action='store_true', help='Enable debug mode with detailed logging')\n    parser.add_argument('--timeout', type=int, default=90, help='Timeout in seconds')\n    return parser\n\ndef validate_arguments(args: argparse.Namespace) -> None:\n    if args.init_config:\n        return\n    if not args.project_path:\n        raise CLIError(\"Project path is required. Use --help for usage information.\")\n    project_path = Path(args.project_path).resolve()\n    if not project_path.exists():\n        raise CLIError(f\"Project path does not exist: {args.project_path}\")\n    if not project_path.is_dir():\n        raise CLIError(f\"Project path is not a directory: {args.project_path}\")\n    python_indicators = ['setup.py', 'pyproject.toml', 'requirements.txt', '__init__.py']\n    has_python_files = any((project_path / indicator).exists() for indicator in python_indicators)\n    has_py_files = any(project_path.glob('**/*.py'))\n    if not has_python_files and not has_py_files:\n        logger.warning(f\"No Python project indicators found in {project_path}\")\n    if args.max_tokens < 1000:\n        raise CLIError(\"Maximum tokens must be at least 1000\")\n    if args.timeout < 1:\n        raise CLIError(\"Timeout must be at least 1 second\")\n    if args.timeout > 300:\n        logger.warning(f\"Timeout of {args.timeout}s exceeds recommended 90s performance target\")\n\ndef validate_api_requirements(model_name: str, api_key: str) -> str:\n    env_key_mapping = {\n        'gemini_2_5_pro': 'GEMINI_API_KEY',\n        'gemini_2_5_flash': 'GEMINI_API_KEY', \n        'gpt_4o': 'OPENAI_API_KEY',\n        'gpt_4o_mini': 'OPENAI_API_KEY',\n        'claude_sonnet': 'ANTHROPIC_API_KEY'\n    }\n    if not api_key:\n        env_var = env_key_mapping.get(model_name)\n        if env_var:\n            api_key = os.getenv(env_var)\n    if not api_key:\n        env_var = env_key_mapping.get(model_name, 'API_KEY')\n        raise CLIError(\n            f\"API key required for {model_name}. Provide via --api-key or {env_var}.\"\n        )\n    if model_name.startswith('gemini') and not genai:\n        raise CLIError(\"google-generativeai package required for Gemini models.\")\n    elif model_name.startswith('gpt') and not openai:\n        raise CLIError(\"openai package required for OpenAI models.\")\n    elif model_name.startswith('claude') and not anthropic:\n        raise CLIError(\"anthropic package required for Claude models.\")\n    return api_key\n\ndef load_configuration(args: argparse.Namespace) -> Config:\n    config = Config()\n    if args.config:\n        try:\n            loaded_config = load_config(args.config)\n            config.update(loaded_config)\n            logger.info(f\"Loaded configuration from {args.config}\")\n        except Exception as e:\n            logger.warning(f\"Failed to load configuration: {e}\")\n    config.model_name = args.model\n    config.max_tokens = args.max_tokens\n    config.include_tests = args.include_tests\n    config.include_private = args.include_private\n    config.verbose = args.verbose\n    config.quiet = args.quiet\n    config.debug = args.debug\n    config.timeout = args.timeout\n    config.cache_enabled = not getattr(args, \"no_cache\", False)\n    if args.api_key:\n        config.api_key = args.api_key\n    return config\n\nasync def generate_readme_with_llm(project_data: dict, config: Config, api_key: str) -> str:\n    # MVP: project_data is a dict from the MVP parser\n    serialized_data = serialize_project_data(project_data)\n    token_count = estimate_tokens(json.dumps(serialized_data))\n    logger.info(f\"Sending ~{token_count:,} tokens to {config.model_name}\")\n    if token_count > config.max_tokens:\n        logger.warning(f\"Token count ({token_count:,}) exceeds limit ({config.max_tokens:,})\")\n    prompt = create_readme_prompt(serialized_data, serialized_data.get('project_metadata', {}).get('name', 'Project'))\n    if config.model_name.startswith('gemini'):\n        return await generate_with_gemini(prompt, api_key)\n    elif config.model_name.startswith('gpt'):\n        return await generate_with_openai(prompt, api_key)\n    elif config.model_name.startswith('claude'):\n        return await generate_with_claude(prompt, api_key)\n    else:\n        raise LLMAPIError(f\"Unsupported model: {config.model_name}\")\n\ndef create_readme_prompt(project_data: dict, project_name: str) -> str:\n    return f\"\"\"You are an expert technical writer specializing in creating comprehensive README files for Python projects.\nGenerate a professional, well-structured README.md file for the project \"{project_name}\" based on the following parsed project information:\n{json.dumps(project_data, indent=2)}\n\nRequirements:\n1. Create a complete README with these essential sections:\n   - Project Description (clear, concise overview)\n   - Installation Instructions\n   - Usage Examples\n   - Project Structure\n   - Dependencies\n   - API Documentation (key classes/functions)\n2. Use proper Markdown formatting.\n3. Be accurate to the actual project structure and dependencies.\nOnly output the README content in Markdown format.\"\"\"\n\nasync def generate_with_gemini(prompt: str, api_key: str) -> str:\n    if not genai:\n        raise LLMAPIError(\"google-generativeai package not available\")\n    try:\n        genai.configure(api_key=api_key)\n        model = genai.GenerativeModel(model_name=\"gemini-2.5-pro\")\n        logger.info(f\"Generating README with Gemini 2.5 Pro\")\n        response = await model.generate_content_async(prompt)\n        if not response.text:\n            raise LLMAPIError(\"No content from Gemini API\")\n        return response.text\n    except Exception as e:\n        raise LLMAPIError(str(e))\n\nasync def generate_with_openai(prompt: str, api_key: str) -> str:\n    if not openai:\n        raise LLMAPIError(\"openai package not available\")\n    try:\n        client = openai.AsyncOpenAI(api_key=api_key)\n        response = await client.chat.completions.create(\n            model='gpt-4o',\n            messages=[{\"role\": \"system\", \"content\": \"You are an expert technical writer.\"},{\"role\": \"user\", \"content\": prompt}],\n            temperature=0.7,\n            max_tokens=4096\n        )\n        if not response.choices or not response.choices[0].message.content:\n            raise LLMAPIError(\"No content from OpenAI API\")\n        return response.choices[0].message.content\n    except Exception as e:\n        raise LLMAPIError(str(e))\n\nasync def generate_with_claude(prompt: str, api_key: str) -> str:\n    if not anthropic:\n        raise LLMAPIError(\"anthropic package not available\")\n    try:\n        client = anthropic.AsyncAnthropic(api_key=api_key)\n        response = await client.messages.create(\n            model=\"claude-3-5-sonnet-20241022\",\n            max_tokens=4096,\n            temperature=0.7,\n            messages=[{\"role\": \"user\", \"content\": prompt}]\n        )\n        if not response.content or not response.content[0].text:\n            raise LLMAPIError(\"No content from Claude API\")\n        return response.content[0].text\n    except Exception as e:\n        raise LLMAPIError(str(e))\n\ndef init_config_command(args: argparse.Namespace) -> None:\n    config_path = \"readme_generator_config.json\"\n    try:\n        config = Config()\n        config.model_name = \"gemini_2_5_pro\"\n        config.max_tokens = 1_000_000\n        config.timeout = 90\n        save_config(config, config_path)\n        print(f\"✓ Configuration file created: {config_path}\")\n        print(\"Edit it to customize settings.\")\n    except Exception as e:\n        raise CLIError(f\"Failed to create configuration file: {e}\")\n\nasync def parse_and_generate_command(args: argparse.Namespace, config: Config) -> None:\n    start_time = time.time()\n    try:\n        project_path = Path(args.project_path).resolve()\n        logger.info(f\"Parsing project: {project_path}\")\n        parsing_start = time.time()\n        # MVP: No return object/results object, just a dict.\n        result = parse_project(str(project_path))\n        parsing_time = time.time() - parsing_start\n\n        if not config.quiet:\n            print(f\"✓ Project parsed in {parsing_time:.2f}s\")\n\n        # Save JSON output\n        json_output_path = args.json_output or f\"{project_path.name}_parsed_data.json\"\n        serialized_data = serialize_project_data(result)\n        success = save_json_to_file(serialized_data, json_output_path)\n        if success and not config.quiet:\n            print(f\"✓ JSON data saved to: {json_output_path}\")\n\n        if args.parse_only:\n            if not config.quiet:\n                print(f\"✓ Parse-only mode completed in {time.time() - start_time:.2f}s\")\n            return\n\n        api_key = validate_api_requirements(config.model_name, config.api_key)\n        if not config.quiet:\n            print(f\"Generating README with {config.model_name}...\")\n\n        generation_start = time.time()\n        readme_content = await generate_readme_with_llm(result, config, api_key)\n        generation_time = time.time() - generation_start\n\n        output_path = Path(args.output)\n        if not output_path.is_absolute():\n            output_path = project_path / output_path\n        create_directory(str(output_path.parent))\n        with open(output_path, 'w', encoding='utf-8') as f:\n            f.write(readme_content)\n        if not config.quiet:\n            print(f\"✓ README generated in {generation_time:.2f}s\")\n            print(f\"✓ README saved to: {output_path}\")\n\n    except Exception as e:\n        elapsed_time = time.time() - start_time\n        logger.error(f\"Command failed after {elapsed_time:.2f}s: {e}\")\n        raise\n\ndef main():\n    try:\n        parser = create_parser()\n        args = parser.parse_args()\n        if args.init_config:\n            init_config_command(args)\n            return\n        validate_arguments(args)\n        config = load_configuration(args)\n        config.parse_only = getattr(args, 'parse_only', False)\n        if config.debug:\n            logging.getLogger().setLevel(logging.DEBUG)\n        elif config.verbose:\n            logging.getLogger().setLevel(logging.INFO)\n        elif config.quiet:\n            logging.getLogger().setLevel(logging.ERROR)\n        if args.save_config:\n            save_config(config, args.save_config)\n            if not config.quiet:\n                print(f\"✓ Configuration saved to: {args.save_config}\")\n        asyncio.run(parse_and_generate_command(args, config))\n    except CLIError as e:\n        print(f\"Error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    except KeyboardInterrupt:\n        print(\"\\nOperation cancelled by user.\")\n        sys.exit(1)\n    except Exception as e:\n        logger.error(f\"Unexpected error: {e}\")\n        print(f\"An unexpected error occurred: {e}\", file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()\n",
        "docstring": "Command-line interface for the README generator.\n\nThis module provides the main CLI functionality for automatically generating\ncomprehensive README files for Python projects using LLM APIs,\noptimized for Gemini 2.5 Pro with a 1M token window.",
        "description": "Command-line interface script",
        "argument_parser": {
          "program_name": "readme-generator",
          "description": "Generate a README for a Python project using LLMs.",
          "arguments": []
        }
      }
    ],
    "setup_scripts": [],
    "package_entry_points": []
  },
  "modules": [
    {
      "name": "cli",
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\cli.py",
      "docstring": "Command-line interface for the README generator.\n\nThis module provides the main CLI functionality for automatically generating\ncomprehensive README files for Python projects using LLM APIs,\noptimized for Gemini 2.5 Pro with a 1M token window.",
      "classes": [
        {
          "name": "CLIError",
          "docstring": null,
          "methods": [],
          "bases": [
            "Exception"
          ],
          "decorators": []
        },
        {
          "name": "LLMAPIError",
          "docstring": null,
          "methods": [],
          "bases": [
            "Exception"
          ],
          "decorators": []
        }
      ],
      "functions": [
        {
          "name": "create_parser",
          "docstring": null,
          "decorators": [],
          "args": []
        },
        {
          "name": "validate_arguments",
          "docstring": null,
          "decorators": [],
          "args": [
            "args"
          ]
        },
        {
          "name": "validate_api_requirements",
          "docstring": null,
          "decorators": [],
          "args": [
            "model_name",
            "api_key"
          ]
        },
        {
          "name": "load_configuration",
          "docstring": null,
          "decorators": [],
          "args": [
            "args"
          ]
        },
        {
          "name": "create_readme_prompt",
          "docstring": null,
          "decorators": [],
          "args": [
            "project_data",
            "project_name"
          ]
        },
        {
          "name": "init_config_command",
          "docstring": null,
          "decorators": [],
          "args": [
            "args"
          ]
        },
        {
          "name": "main",
          "docstring": null,
          "decorators": [],
          "args": []
        }
      ],
      "imports": [
        "os",
        "sys",
        "argparse",
        "time",
        "json",
        "asyncio",
        "from pathlib import Path",
        "logging",
        "from config import Config",
        "from config import load_config",
        "from config import save_config",
        "from parser.project_parser import parse_project",
        "from utils.token_counter import estimate_tokens",
        "from utils.file_utils import create_directory",
        "from utils.json_serializer import serialize_project_data",
        "from utils.json_serializer import save_json_to_file"
      ],
      "constants": [],
      "source_code": "\"\"\"\nCommand-line interface for the README generator.\n\nThis module provides the main CLI functionality for automatically generating\ncomprehensive README files for Python projects using LLM APIs,\noptimized for Gemini 2.5 Pro with a 1M token window.\n\"\"\"\n\nimport os\nimport sys\nimport argparse\nimport time\nimport json\nimport asyncio\nfrom pathlib import Path\nimport logging\n\n# Optional: Third-party LLM APIs\ntry:\n    import google.generativeai as genai\nexcept ImportError:\n    genai = None\n\ntry:\n    import openai\nexcept ImportError:\n    openai = None\n\ntry:\n    import anthropic\nexcept ImportError:\n    anthropic = None\n\nfrom config import Config, load_config, save_config\nfrom parser.project_parser import parse_project\nfrom utils.token_counter import estimate_tokens\nfrom utils.file_utils import create_directory\nfrom utils.json_serializer import serialize_project_data, save_json_to_file\n\nlogger = logging.getLogger(__name__)\n\nclass CLIError(Exception):\n    pass\n\nclass LLMAPIError(Exception):\n    pass\n\ndef create_parser() -> argparse.ArgumentParser:\n    parser = argparse.ArgumentParser(\n        prog=\"readme-generator\",\n        description=\"Generate a README for a Python project using LLMs.\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        epilog=\"\"\"\nExamples:\n  readme-generator /path/to/project\n  readme-generator . --output custom_readme.md\n  readme-generator /path/to/project --model gemini_2_5_pro\n  readme-generator /path/to/project --api-key YOUR_API_KEY\n  readme-generator --init-config\n\nPerformance Target:\n  Generates README for projects up to 25 files/5,000 lines in under 90 seconds\n        \"\"\"\n    )\n    parser.add_argument('--version', action='version', version='%(prog)s 1.0')\n    parser.add_argument('--parse-only', action='store_true', help='Only parse project data to JSON, skip README generation')\n    parser.add_argument('project_path', nargs='?', help='Path to the Python project root directory')\n    parser.add_argument('--output', '-o', type=str, default='README.md', help='Output README file path')\n    parser.add_argument('--json-output', type=str, help='Save parsed project data as JSON file')\n    parser.add_argument('--model', choices=['gemini_2_5_pro', 'gemini_2_5_flash', 'gpt_4o', 'gpt_4o_mini', 'claude_sonnet'], default='gemini_2_5_pro', help='LLM model to use')\n    parser.add_argument('--api-key', type=str, help='API key for LLM service')\n    parser.add_argument('--max-tokens', type=int, default=1_000_000, help='Maximum token budget')\n    parser.add_argument('--include-tests', action='store_true', help='Include test files in analysis')\n    parser.add_argument('--include-private', action='store_true', help='Include private methods and classes')\n    parser.add_argument('--config', type=str, help='Path to configuration file')\n    parser.add_argument('--init-config', action='store_true', help='Initialize configuration file with default settings')\n    parser.add_argument('--save-config', type=str, help='Save current settings to configuration file')\n    parser.add_argument('--verbose', '-v', action='store_true', help='Enable verbose output')\n    parser.add_argument('--quiet', '-q', action='store_true', help='Suppress non-error output')\n    parser.add_argument('--debug', action='store_true', help='Enable debug mode with detailed logging')\n    parser.add_argument('--timeout', type=int, default=90, help='Timeout in seconds')\n    return parser\n\ndef validate_arguments(args: argparse.Namespace) -> None:\n    if args.init_config:\n        return\n    if not args.project_path:\n        raise CLIError(\"Project path is required. Use --help for usage information.\")\n    project_path = Path(args.project_path).resolve()\n    if not project_path.exists():\n        raise CLIError(f\"Project path does not exist: {args.project_path}\")\n    if not project_path.is_dir():\n        raise CLIError(f\"Project path is not a directory: {args.project_path}\")\n    python_indicators = ['setup.py', 'pyproject.toml', 'requirements.txt', '__init__.py']\n    has_python_files = any((project_path / indicator).exists() for indicator in python_indicators)\n    has_py_files = any(project_path.glob('**/*.py'))\n    if not has_python_files and not has_py_files:\n        logger.warning(f\"No Python project indicators found in {project_path}\")\n    if args.max_tokens < 1000:\n        raise CLIError(\"Maximum tokens must be at least 1000\")\n    if args.timeout < 1:\n        raise CLIError(\"Timeout must be at least 1 second\")\n    if args.timeout > 300:\n        logger.warning(f\"Timeout of {args.timeout}s exceeds recommended 90s performance target\")\n\ndef validate_api_requirements(model_name: str, api_key: str) -> str:\n    env_key_mapping = {\n        'gemini_2_5_pro': 'GEMINI_API_KEY',\n        'gemini_2_5_flash': 'GEMINI_API_KEY', \n        'gpt_4o': 'OPENAI_API_KEY',\n        'gpt_4o_mini': 'OPENAI_API_KEY',\n        'claude_sonnet': 'ANTHROPIC_API_KEY'\n    }\n    if not api_key:\n        env_var = env_key_mapping.get(model_name)\n        if env_var:\n            api_key = os.getenv(env_var)\n    if not api_key:\n        env_var = env_key_mapping.get(model_name, 'API_KEY')\n        raise CLIError(\n            f\"API key required for {model_name}. Provide via --api-key or {env_var}.\"\n        )\n    if model_name.startswith('gemini') and not genai:\n        raise CLIError(\"google-generativeai package required for Gemini models.\")\n    elif model_name.startswith('gpt') and not openai:\n        raise CLIError(\"openai package required for OpenAI models.\")\n    elif model_name.startswith('claude') and not anthropic:\n        raise CLIError(\"anthropic package required for Claude models.\")\n    return api_key\n\ndef load_configuration(args: argparse.Namespace) -> Config:\n    config = Config()\n    if args.config:\n        try:\n            loaded_config = load_config(args.config)\n            config.update(loaded_config)\n            logger.info(f\"Loaded configuration from {args.config}\")\n        except Exception as e:\n            logger.warning(f\"Failed to load configuration: {e}\")\n    config.model_name = args.model\n    config.max_tokens = args.max_tokens\n    config.include_tests = args.include_tests\n    config.include_private = args.include_private\n    config.verbose = args.verbose\n    config.quiet = args.quiet\n    config.debug = args.debug\n    config.timeout = args.timeout\n    config.cache_enabled = not getattr(args, \"no_cache\", False)\n    if args.api_key:\n        config.api_key = args.api_key\n    return config\n\nasync def generate_readme_with_llm(project_data: dict, config: Config, api_key: str) -> str:\n    # MVP: project_data is a dict from the MVP parser\n    serialized_data = serialize_project_data(project_data)\n    token_count = estimate_tokens(json.dumps(serialized_data))\n    logger.info(f\"Sending ~{token_count:,} tokens to {config.model_name}\")\n    if token_count > config.max_tokens:\n        logger.warning(f\"Token count ({token_count:,}) exceeds limit ({config.max_tokens:,})\")\n    prompt = create_readme_prompt(serialized_data, serialized_data.get('project_metadata', {}).get('name', 'Project'))\n    if config.model_name.startswith('gemini'):\n        return await generate_with_gemini(prompt, api_key)\n    elif config.model_name.startswith('gpt'):\n        return await generate_with_openai(prompt, api_key)\n    elif config.model_name.startswith('claude'):\n        return await generate_with_claude(prompt, api_key)\n    else:\n        raise LLMAPIError(f\"Unsupported model: {config.model_name}\")\n\ndef create_readme_prompt(project_data: dict, project_name: str) -> str:\n    return f\"\"\"You are an expert technical writer specializing in creating comprehensive README files for Python projects.\nGenerate a professional, well-structured README.md file for the project \"{project_name}\" based on the following parsed project information:\n{json.dumps(project_data, indent=2)}\n\nRequirements:\n1. Create a complete README with these essential sections:\n   - Project Description (clear, concise overview)\n   - Installation Instructions\n   - Usage Examples\n   - Project Structure\n   - Dependencies\n   - API Documentation (key classes/functions)\n2. Use proper Markdown formatting.\n3. Be accurate to the actual project structure and dependencies.\nOnly output the README content in Markdown format.\"\"\"\n\nasync def generate_with_gemini(prompt: str, api_key: str) -> str:\n    if not genai:\n        raise LLMAPIError(\"google-generativeai package not available\")\n    try:\n        genai.configure(api_key=api_key)\n        model = genai.GenerativeModel(model_name=\"gemini-2.5-pro\")\n        logger.info(f\"Generating README with Gemini 2.5 Pro\")\n        response = await model.generate_content_async(prompt)\n        if not response.text:\n            raise LLMAPIError(\"No content from Gemini API\")\n        return response.text\n    except Exception as e:\n        raise LLMAPIError(str(e))\n\nasync def generate_with_openai(prompt: str, api_key: str) -> str:\n    if not openai:\n        raise LLMAPIError(\"openai package not available\")\n    try:\n        client = openai.AsyncOpenAI(api_key=api_key)\n        response = await client.chat.completions.create(\n            model='gpt-4o',\n            messages=[{\"role\": \"system\", \"content\": \"You are an expert technical writer.\"},{\"role\": \"user\", \"content\": prompt}],\n            temperature=0.7,\n            max_tokens=4096\n        )\n        if not response.choices or not response.choices[0].message.content:\n            raise LLMAPIError(\"No content from OpenAI API\")\n        return response.choices[0].message.content\n    except Exception as e:\n        raise LLMAPIError(str(e))\n\nasync def generate_with_claude(prompt: str, api_key: str) -> str:\n    if not anthropic:\n        raise LLMAPIError(\"anthropic package not available\")\n    try:\n        client = anthropic.AsyncAnthropic(api_key=api_key)\n        response = await client.messages.create(\n            model=\"claude-3-5-sonnet-20241022\",\n            max_tokens=4096,\n            temperature=0.7,\n            messages=[{\"role\": \"user\", \"content\": prompt}]\n        )\n        if not response.content or not response.content[0].text:\n            raise LLMAPIError(\"No content from Claude API\")\n        return response.content[0].text\n    except Exception as e:\n        raise LLMAPIError(str(e))\n\ndef init_config_command(args: argparse.Namespace) -> None:\n    config_path = \"readme_generator_config.json\"\n    try:\n        config = Config()\n        config.model_name = \"gemini_2_5_pro\"\n        config.max_tokens = 1_000_000\n        config.timeout = 90\n        save_config(config, config_path)\n        print(f\"✓ Configuration file created: {config_path}\")\n        print(\"Edit it to customize settings.\")\n    except Exception as e:\n        raise CLIError(f\"Failed to create configuration file: {e}\")\n\nasync def parse_and_generate_command(args: argparse.Namespace, config: Config) -> None:\n    start_time = time.time()\n    try:\n        project_path = Path(args.project_path).resolve()\n        logger.info(f\"Parsing project: {project_path}\")\n        parsing_start = time.time()\n        # MVP: No return object/results object, just a dict.\n        result = parse_project(str(project_path))\n        parsing_time = time.time() - parsing_start\n\n        if not config.quiet:\n            print(f\"✓ Project parsed in {parsing_time:.2f}s\")\n\n        # Save JSON output\n        json_output_path = args.json_output or f\"{project_path.name}_parsed_data.json\"\n        serialized_data = serialize_project_data(result)\n        success = save_json_to_file(serialized_data, json_output_path)\n        if success and not config.quiet:\n            print(f\"✓ JSON data saved to: {json_output_path}\")\n\n        if args.parse_only:\n            if not config.quiet:\n                print(f\"✓ Parse-only mode completed in {time.time() - start_time:.2f}s\")\n            return\n\n        api_key = validate_api_requirements(config.model_name, config.api_key)\n        if not config.quiet:\n            print(f\"Generating README with {config.model_name}...\")\n\n        generation_start = time.time()\n        readme_content = await generate_readme_with_llm(result, config, api_key)\n        generation_time = time.time() - generation_start\n\n        output_path = Path(args.output)\n        if not output_path.is_absolute():\n            output_path = project_path / output_path\n        create_directory(str(output_path.parent))\n        with open(output_path, 'w', encoding='utf-8') as f:\n            f.write(readme_content)\n        if not config.quiet:\n            print(f\"✓ README generated in {generation_time:.2f}s\")\n            print(f\"✓ README saved to: {output_path}\")\n\n    except Exception as e:\n        elapsed_time = time.time() - start_time\n        logger.error(f\"Command failed after {elapsed_time:.2f}s: {e}\")\n        raise\n\ndef main():\n    try:\n        parser = create_parser()\n        args = parser.parse_args()\n        if args.init_config:\n            init_config_command(args)\n            return\n        validate_arguments(args)\n        config = load_configuration(args)\n        config.parse_only = getattr(args, 'parse_only', False)\n        if config.debug:\n            logging.getLogger().setLevel(logging.DEBUG)\n        elif config.verbose:\n            logging.getLogger().setLevel(logging.INFO)\n        elif config.quiet:\n            logging.getLogger().setLevel(logging.ERROR)\n        if args.save_config:\n            save_config(config, args.save_config)\n            if not config.quiet:\n                print(f\"✓ Configuration saved to: {args.save_config}\")\n        asyncio.run(parse_and_generate_command(args, config))\n    except CLIError as e:\n        print(f\"Error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    except KeyboardInterrupt:\n        print(\"\\nOperation cancelled by user.\")\n        sys.exit(1)\n    except Exception as e:\n        logger.error(f\"Unexpected error: {e}\")\n        print(f\"An unexpected error occurred: {e}\", file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()\n"
    },
    {
      "name": "config",
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\config.py",
      "docstring": "Configuration management for the README generator.\n\nThis module handles loading, saving, and managing configuration settings\nfor the README generation tool, including model settings, parsing options,\nand output preferences.",
      "classes": [
        {
          "name": "Config",
          "docstring": "Configuration settings for the README generator.",
          "methods": [
            {
              "name": "__post_init__",
              "docstring": "Post-initialization setup.",
              "decorators": [],
              "args": [
                "self"
              ]
            },
            {
              "name": "_get_api_key_from_env",
              "docstring": "Get API key from environment variables.",
              "decorators": [],
              "args": [
                "self"
              ]
            },
            {
              "name": "update",
              "docstring": "Update configuration with values from another config or dictionary.",
              "decorators": [],
              "args": [
                "self",
                "other"
              ]
            },
            {
              "name": "validate",
              "docstring": "Validate configuration settings.",
              "decorators": [],
              "args": [
                "self"
              ]
            },
            {
              "name": "get_cache_path",
              "docstring": "Get the cache directory path.",
              "decorators": [],
              "args": [
                "self"
              ]
            },
            {
              "name": "get_model_config",
              "docstring": "Get model-specific configuration.",
              "decorators": [],
              "args": [
                "self"
              ]
            },
            {
              "name": "to_dict",
              "docstring": "Convert configuration to dictionary.",
              "decorators": [],
              "args": [
                "self"
              ]
            },
            {
              "name": "from_dict",
              "docstring": "Create configuration from dictionary.",
              "decorators": [
                "classmethod"
              ],
              "args": [
                "cls",
                "data"
              ]
            }
          ],
          "bases": [],
          "decorators": [
            "dataclass"
          ]
        }
      ],
      "functions": [
        {
          "name": "get_default_config_path",
          "docstring": "Get the default configuration file path.",
          "decorators": [],
          "args": []
        },
        {
          "name": "load_config",
          "docstring": "Load configuration from file.\n\nArgs:\n    config_path: Path to configuration file. If None, uses default location.\n    \nReturns:\n    Config object loaded from file\n    \nRaises:\n    FileNotFoundError: If configuration file doesn't exist\n    ValueError: If configuration file is invalid",
          "decorators": [],
          "args": [
            "config_path"
          ]
        },
        {
          "name": "save_config",
          "docstring": "Save configuration to file.\n\nArgs:\n    config: Configuration object to save\n    config_path: Path to save configuration file. If None, uses default location.\n    \nRaises:\n    ValueError: If configuration is invalid\n    IOError: If unable to write to file",
          "decorators": [],
          "args": [
            "config",
            "config_path"
          ]
        },
        {
          "name": "create_default_config",
          "docstring": "Create a default configuration object.",
          "decorators": [],
          "args": []
        },
        {
          "name": "get_config_template",
          "docstring": "Get a configuration template with comments.",
          "decorators": [],
          "args": []
        },
        {
          "name": "merge_configs",
          "docstring": "Merge two configurations, with override taking precedence.\n\nArgs:\n    base_config: Base configuration object\n    override_config: Dictionary of override values\n    \nReturns:\n    New Config object with merged values",
          "decorators": [],
          "args": [
            "base_config",
            "override_config"
          ]
        },
        {
          "name": "init_config_file",
          "docstring": "Initialize a configuration file with default values.\n\nArgs:\n    config_path: Path to create configuration file\n    template: Whether to create a template with comments",
          "decorators": [],
          "args": [
            "config_path",
            "template"
          ]
        },
        {
          "name": "validate_config_file",
          "docstring": "Validate a configuration file.\n\nArgs:\n    config_path: Path to configuration file\n    \nReturns:\n    True if valid, False otherwise",
          "decorators": [],
          "args": [
            "config_path"
          ]
        }
      ],
      "imports": [
        "json",
        "os",
        "from pathlib import Path",
        "from typing import Dict",
        "from typing import Any",
        "from typing import Optional",
        "from typing import Union",
        "from dataclasses import dataclass",
        "from dataclasses import asdict",
        "from dataclasses import field",
        "logging"
      ],
      "constants": []
    },
    {
      "name": "__init__",
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\__init__.py",
      "docstring": "README Generator - Automated README generation for Python projects.\n\nThis package provides a command-line tool that automatically generates comprehensive\nREADME files for Python projects using Large Language Model APIs. It intelligently\nparses and extracts key information from codebases to create high-quality documentation\nwithin LLM context window constraints.\n\nFeatures:\n- Comprehensive project analysis and parsing\n- Token-aware content optimization for LLM APIs\n- Multiple LLM provider support (Gemini, OpenAI, Claude)\n- Intelligent content prioritization\n- Error handling and graceful degradation",
      "classes": [],
      "functions": [
        {
          "name": "get_version",
          "docstring": "Get the current version of the package.",
          "decorators": [],
          "args": []
        },
        {
          "name": "get_package_info",
          "docstring": "Get comprehensive package information.",
          "decorators": [],
          "args": []
        }
      ],
      "imports": [
        "from parser.project_parser import parse_project",
        "from parser.project_parser import parse_project_to_json",
        "from utils.token_counter import estimate_tokens",
        "from utils.token_counter import count_tokens_in_text",
        "from utils.content_prioritizer import prioritize_project_data",
        "from utils.json_serializer import serialize_project_data",
        "from config import Config",
        "from config import load_config",
        "from config import save_config"
      ],
      "constants": []
    },
    {
      "name": "__main__",
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\__main__.py",
      "docstring": "CLI entry point for the README generator package.\n\nThis module provides the main entry point when the package is run as a module\nusing 'python -m readme_generator'. It handles command-line argument parsing\nand delegates to the appropriate CLI functions.",
      "classes": [],
      "functions": [
        {
          "name": "setup_logging",
          "docstring": "Set up logging configuration.",
          "decorators": [],
          "args": [
            "verbose"
          ]
        },
        {
          "name": "check_python_version",
          "docstring": "Check if Python version is compatible.",
          "decorators": [],
          "args": []
        },
        {
          "name": "handle_exceptions",
          "docstring": "Set up global exception handling.",
          "decorators": [],
          "args": []
        },
        {
          "name": "entry_point",
          "docstring": "Main entry point for the CLI application.",
          "decorators": [],
          "args": []
        }
      ],
      "imports": [
        "sys",
        "os",
        "logging",
        "from pathlib import Path",
        "from cli import main"
      ],
      "constants": [],
      "source_code": "\"\"\"\nCLI entry point for the README generator package.\n\nThis module provides the main entry point when the package is run as a module\nusing 'python -m readme_generator'. It handles command-line argument parsing\nand delegates to the appropriate CLI functions.\n\"\"\"\n\nimport sys\nimport os\nimport logging\nfrom pathlib import Path\n\n# Add the package to Python path if running as script\nif __name__ == \"__main__\":\n    # Get the directory containing this file\n    current_dir = Path(__file__).parent\n    # Add parent directory to path so we can import the package\n    sys.path.insert(0, str(current_dir.parent))\n\nfrom cli import main\n\n\ndef setup_logging(verbose: bool = False):\n    \"\"\"Set up logging configuration.\"\"\"\n    log_level = logging.DEBUG if verbose else logging.INFO\n    \n    # Create formatter\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n    )\n    \n    # Set up console handler\n    console_handler = logging.StreamHandler(sys.stdout)\n    console_handler.setFormatter(formatter)\n    \n    # Configure root logger\n    root_logger = logging.getLogger()\n    root_logger.setLevel(log_level)\n    root_logger.addHandler(console_handler)\n    \n    # Reduce noise from third-party libraries\n    logging.getLogger('urllib3').setLevel(logging.WARNING)\n    logging.getLogger('requests').setLevel(logging.WARNING)\n    logging.getLogger('httpx').setLevel(logging.WARNING)\n\n\ndef check_python_version():\n    \"\"\"Check if Python version is compatible.\"\"\"\n    if sys.version_info < (3, 8):\n        print(\"Error: Python 3.8 or higher is required.\")\n        print(f\"You are using Python {sys.version}\")\n        sys.exit(1)\n\n\ndef handle_exceptions():\n    \"\"\"Set up global exception handling.\"\"\"\n    def exception_handler(exc_type, exc_value, exc_traceback):\n        if issubclass(exc_type, KeyboardInterrupt):\n            print(\"\\nOperation cancelled by user.\")\n            sys.exit(1)\n        else:\n            # Log the exception\n            logging.error(\n                \"Uncaught exception\", \n                exc_info=(exc_type, exc_value, exc_traceback)\n            )\n            print(f\"An unexpected error occurred: {exc_value}\")\n            sys.exit(1)\n    \n    sys.excepthook = exception_handler\n\n\ndef entry_point():\n    \"\"\"Main entry point for the CLI application.\"\"\"\n    try:\n        # Check Python version compatibility\n        check_python_version()\n        \n        # Set up global exception handling\n        handle_exceptions()\n        \n        # Parse arguments and determine verbosity early\n        verbose = '--verbose' in sys.argv or '-v' in sys.argv\n        \n        # Set up logging\n        setup_logging(verbose)\n        \n        # Log startup information\n        logger = logging.getLogger(__name__)\n        logger.info(f\"Starting README Generator v{get_version()}\")\n        logger.debug(f\"Python version: {sys.version}\")\n        logger.debug(f\"Command line arguments: {sys.argv}\")\n        \n        # Run the main CLI function\n        main()\n        \n    except Exception as e:\n        print(f\"Failed to start README Generator: {e}\")\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    # Import version info\n    try:\n        from readme_generator import get_version\n    except ImportError:\n        def get_version():\n            return \"0.1.0\"\n    \n    entry_point()\n"
    },
    {
      "name": "code_parser",
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\code_parser.py",
      "docstring": null,
      "classes": [],
      "functions": [
        {
          "name": "parse_code_file",
          "docstring": "Parse a Python file and extract detailed information including full code for entry points.\n\nArgs:\n    file_path: Path to the Python file\n    extract_full_code: Whether to include full source code (for entry points)",
          "decorators": [],
          "args": [
            "file_path",
            "extract_full_code"
          ]
        },
        {
          "name": "_get_name_from_node",
          "docstring": "Helper to extract name from AST node.",
          "decorators": [],
          "args": [
            "node"
          ]
        }
      ],
      "imports": [
        "ast",
        "from pathlib import Path",
        "from typing import Optional",
        "from typing import Dict",
        "from typing import Any",
        "from typing import List"
      ],
      "constants": []
    },
    {
      "name": "dependency_parser",
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\dependency_parser.py",
      "docstring": null,
      "classes": [],
      "functions": [
        {
          "name": "parse_dependencies",
          "docstring": "Extract dependencies from multiple sources:\n- pyproject.toml\n- setup.py\n- setup.cfg  \n- requirements.txt files\n- Pipfile\n- environment.yml",
          "decorators": [],
          "args": [
            "project_path"
          ]
        },
        {
          "name": "_parse_pyproject_dependencies",
          "docstring": "Parse dependencies from pyproject.toml.",
          "decorators": [],
          "args": [
            "project_path"
          ]
        },
        {
          "name": "_parse_setup_py_dependencies",
          "docstring": "Parse dependencies from setup.py.",
          "decorators": [],
          "args": [
            "project_path"
          ]
        },
        {
          "name": "_extract_setup_dependencies_ast",
          "docstring": "Extract dependencies from setup() call using AST.",
          "decorators": [],
          "args": [
            "tree"
          ]
        },
        {
          "name": "_extract_setup_dependencies_regex",
          "docstring": "Extract dependencies using regex patterns.",
          "decorators": [],
          "args": [
            "content"
          ]
        },
        {
          "name": "_parse_setup_cfg_dependencies",
          "docstring": "Parse dependencies from setup.cfg.",
          "decorators": [],
          "args": [
            "project_path"
          ]
        },
        {
          "name": "_parse_requirements_files",
          "docstring": "Parse dependencies from requirements files.",
          "decorators": [],
          "args": [
            "project_path"
          ]
        },
        {
          "name": "_parse_pipfile_dependencies",
          "docstring": "Parse dependencies from Pipfile.",
          "decorators": [],
          "args": [
            "project_path"
          ]
        },
        {
          "name": "_parse_conda_dependencies",
          "docstring": "Parse dependencies from conda environment files.",
          "decorators": [],
          "args": [
            "project_path"
          ]
        }
      ],
      "imports": [
        "ast",
        "re",
        "from pathlib import Path",
        "from typing import List",
        "from typing import Dict",
        "from typing import Any"
      ],
      "constants": []
    },
    {
      "name": "entry_point_parser",
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\entry_point_parser.py",
      "docstring": "Parser for identifying and extracting entry points and main scripts.\nThese are crucial for generating usage instructions in READMEs.",
      "classes": [],
      "functions": [
        {
          "name": "parse_entry_points",
          "docstring": "Identify and extract entry points including CLI scripts, main modules, and setup.py scripts.",
          "decorators": [],
          "args": [
            "project_path"
          ]
        },
        {
          "name": "_extract_main_module_info",
          "docstring": "Extract information from __main__.py files.",
          "decorators": [],
          "args": [
            "main_file"
          ]
        },
        {
          "name": "_extract_cli_script_info",
          "docstring": "Extract information from CLI script files.",
          "decorators": [],
          "args": [
            "cli_file"
          ]
        },
        {
          "name": "_extract_setup_entry_points",
          "docstring": "Extract console scripts and entry points from setup.py.",
          "decorators": [],
          "args": [
            "setup_file"
          ]
        },
        {
          "name": "_extract_pyproject_entry_points",
          "docstring": "Extract entry points from pyproject.toml.",
          "decorators": [],
          "args": [
            "pyproject_file"
          ]
        },
        {
          "name": "_get_package_name_from_main",
          "docstring": "Get package name from __main__.py file path.",
          "decorators": [],
          "args": [
            "main_file"
          ]
        },
        {
          "name": "_extract_module_docstring",
          "docstring": "Extract module-level docstring.",
          "decorators": [],
          "args": [
            "source"
          ]
        },
        {
          "name": "_is_cli_script",
          "docstring": "Check if source code looks like a CLI script.",
          "decorators": [],
          "args": [
            "source"
          ]
        },
        {
          "name": "_extract_argument_parser_info",
          "docstring": "Extract information about argument parser from CLI script.",
          "decorators": [],
          "args": [
            "source"
          ]
        },
        {
          "name": "_parse_entry_points_dict",
          "docstring": "Parse entry_points dictionary from setup.py AST node.",
          "decorators": [],
          "args": [
            "node"
          ]
        },
        {
          "name": "_parse_scripts_list",
          "docstring": "Parse scripts list from setup.py AST node.",
          "decorators": [],
          "args": [
            "node"
          ]
        }
      ],
      "imports": [
        "ast",
        "os",
        "from pathlib import Path",
        "from typing import List",
        "from typing import Dict",
        "from typing import Any"
      ],
      "constants": []
    },
    {
      "name": "example_parser",
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\example_parser.py",
      "docstring": null,
      "classes": [],
      "functions": [
        {
          "name": "parse_examples",
          "docstring": "Extract code examples from multiple sources:\n- Docstring examples (doctest format)\n- Code blocks in docstrings\n- Main guard blocks\n- Function/class usage patterns\n- Comments with example code",
          "decorators": [],
          "args": [
            "file_path"
          ]
        },
        {
          "name": "_extract_docstring_examples",
          "docstring": "Extract examples from docstrings (doctests and code blocks).",
          "decorators": [],
          "args": [
            "tree",
            "file_path",
            "source"
          ]
        },
        {
          "name": "_parse_docstring_for_examples",
          "docstring": "Parse a docstring for various types of examples.",
          "decorators": [],
          "args": [
            "docstring",
            "file_path",
            "context"
          ]
        },
        {
          "name": "_extract_doctest_examples",
          "docstring": "Extract doctest-style examples (>>> format).",
          "decorators": [],
          "args": [
            "docstring"
          ]
        },
        {
          "name": "_extract_code_blocks",
          "docstring": "Extract code blocks from markdown-style formatting.",
          "decorators": [],
          "args": [
            "docstring"
          ]
        },
        {
          "name": "_extract_example_sections",
          "docstring": "Extract dedicated example sections.",
          "decorators": [],
          "args": [
            "docstring"
          ]
        },
        {
          "name": "_extract_main_guard_examples",
          "docstring": "Extract examples from if __name__ == '__main__': blocks.",
          "decorators": [],
          "args": [
            "tree",
            "file_path",
            "source"
          ]
        },
        {
          "name": "_extract_comment_examples",
          "docstring": "Extract examples from comments.",
          "decorators": [],
          "args": [
            "source",
            "file_path"
          ]
        },
        {
          "name": "_extract_usage_patterns",
          "docstring": "Extract common usage patterns from the code itself.",
          "decorators": [],
          "args": [
            "tree",
            "file_path",
            "source"
          ]
        }
      ],
      "imports": [
        "ast",
        "re",
        "from pathlib import Path",
        "from typing import List",
        "from typing import Dict",
        "from typing import Any"
      ],
      "constants": []
    },
    {
      "name": "metadata_parser",
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\metadata_parser.py",
      "docstring": null,
      "classes": [],
      "functions": [
        {
          "name": "parse_metadata",
          "docstring": "Extract project metadata from multiple sources:\n- pyproject.toml\n- setup.py  \n- setup.cfg\n- __init__.py files\n- README files\n- Project directory structure",
          "decorators": [],
          "args": [
            "project_path"
          ]
        },
        {
          "name": "_parse_pyproject_toml",
          "docstring": "Parse pyproject.toml for project metadata.",
          "decorators": [],
          "args": [
            "project_path"
          ]
        },
        {
          "name": "_parse_setup_py",
          "docstring": "Parse setup.py for project metadata.",
          "decorators": [],
          "args": [
            "project_path"
          ]
        },
        {
          "name": "_extract_setup_call_metadata",
          "docstring": "Extract metadata from setup() call in AST.",
          "decorators": [],
          "args": [
            "tree"
          ]
        },
        {
          "name": "_extract_setup_regex_metadata",
          "docstring": "Extract metadata using regex patterns.",
          "decorators": [],
          "args": [
            "content"
          ]
        },
        {
          "name": "_parse_setup_cfg",
          "docstring": "Parse setup.cfg for project metadata.",
          "decorators": [],
          "args": [
            "project_path"
          ]
        },
        {
          "name": "_parse_init_files",
          "docstring": "Extract metadata from __init__.py files.",
          "decorators": [],
          "args": [
            "project_path"
          ]
        },
        {
          "name": "_parse_readme",
          "docstring": "Extract metadata from README files.",
          "decorators": [],
          "args": [
            "project_path"
          ]
        }
      ],
      "imports": [
        "ast",
        "os",
        "re",
        "from pathlib import Path",
        "from typing import Dict",
        "from typing import Any",
        "from typing import Optional"
      ],
      "constants": []
    },
    {
      "name": "project_parser",
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\project_parser.py",
      "docstring": null,
      "classes": [],
      "functions": [
        {
          "name": "parse_project",
          "docstring": "Orchestrate comprehensive parsing of Python project including entry points.",
          "decorators": [],
          "args": [
            "project_path",
            "include_tests",
            "include_private"
          ]
        },
        {
          "name": "_is_likely_entry_point",
          "docstring": "Check if a file is likely an entry point based on naming patterns.",
          "decorators": [],
          "args": [
            "file_path"
          ]
        }
      ],
      "imports": [
        "from pathlib import Path",
        "from typing import Any",
        "from typing import Dict",
        "from typing import List",
        "from parser.metadata_parser import parse_metadata",
        "from parser.dependency_parser import parse_dependencies",
        "from parser.structure_parser import parse_structure",
        "from parser.example_parser import parse_examples",
        "from parser.code_parser import parse_code_file",
        "from parser.entry_point_parser import parse_entry_points"
      ],
      "constants": []
    },
    {
      "name": "structure_parser",
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\structure_parser.py",
      "docstring": null,
      "classes": [],
      "functions": [
        {
          "name": "parse_structure",
          "docstring": "Traverse project directory and find all Python (.py) files,\nreturning a list of dicts with keys: 'file' (full path) and 'name' (module name).\nIgnores folders named __pycache__, venv, build, dist, tests, docs.",
          "decorators": [],
          "args": [
            "project_path"
          ]
        }
      ],
      "imports": [
        "os",
        "from pathlib import Path"
      ],
      "constants": []
    },
    {
      "name": "__init__",
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\__init__.py",
      "docstring": null,
      "classes": [],
      "functions": [],
      "imports": [],
      "constants": []
    },
    {
      "name": "content_prioritizer",
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\utils\\content_prioritizer.py",
      "docstring": null,
      "classes": [],
      "functions": [
        {
          "name": "filter_content_under_token_limit",
          "docstring": "Yield as many items as fit under max_tokens (approx).",
          "decorators": [],
          "args": [
            "items",
            "max_tokens"
          ]
        }
      ],
      "imports": [],
      "constants": []
    },
    {
      "name": "file_utils",
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\utils\\file_utils.py",
      "docstring": "File system utilities for safe and efficient file operations.\n\nThis module provides functions for reading files, detecting encodings,\nand basic directory traversal for Python projects.",
      "classes": [],
      "functions": [
        {
          "name": "read_file_safely",
          "docstring": "Reads file contents if file size is below max_size.",
          "decorators": [],
          "args": [
            "file_path",
            "max_size"
          ]
        },
        {
          "name": "create_directory",
          "docstring": "Create directory if it doesn't exist.",
          "decorators": [],
          "args": [
            "path"
          ]
        },
        {
          "name": "find_python_files",
          "docstring": "Yield all Python file paths in project, optionally skipping test folders.",
          "decorators": [],
          "args": [
            "project_path",
            "include_tests"
          ]
        }
      ],
      "imports": [
        "os",
        "mimetypes",
        "from pathlib import Path",
        "from typing import Optional",
        "from typing import Generator",
        "logging"
      ],
      "constants": []
    },
    {
      "name": "json_serializer",
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\utils\\json_serializer.py",
      "docstring": "JSON serialization utilities for project data output.\n\nThis module provides functions to serialize Python dict/list project data\nto JSON files with proper formatting and error handling.",
      "classes": [],
      "functions": [
        {
          "name": "serialize_project_data",
          "docstring": "Serialize project data; mono pass-through for MVP.\nThis can be extended if richer processing is required.",
          "decorators": [],
          "args": [
            "data"
          ]
        },
        {
          "name": "format_json_output",
          "docstring": "Format data as pretty JSON string.",
          "decorators": [],
          "args": [
            "data",
            "indent"
          ]
        },
        {
          "name": "save_json_to_file",
          "docstring": "Save data as JSON to the given filepath.\nReturns True on success, False on failure.",
          "decorators": [],
          "args": [
            "data",
            "file_path",
            "indent"
          ]
        },
        {
          "name": "load_json_from_file",
          "docstring": "Load and parse JSON file to dict.",
          "decorators": [],
          "args": [
            "file_path"
          ]
        }
      ],
      "imports": [
        "json",
        "from typing import Any",
        "from typing import Dict",
        "from typing import Optional",
        "from pathlib import Path",
        "logging"
      ],
      "constants": []
    },
    {
      "name": "token_counter",
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\utils\\token_counter.py",
      "docstring": "Token counting and estimation utilities for LLM context budgets.\n\nThis module provides rough token estimates for strings,\nappropriate for planning LLM prompt sizes.",
      "classes": [],
      "functions": [
        {
          "name": "estimate_tokens",
          "docstring": "Rough token estimate based on character count (~4 chars per token).",
          "decorators": [],
          "args": [
            "text"
          ]
        },
        {
          "name": "count_tokens_in_dict",
          "docstring": "Estimate tokens in a dict by JSON serialization length.",
          "decorators": [],
          "args": [
            "data"
          ]
        }
      ],
      "imports": [
        "json",
        "logging"
      ],
      "constants": []
    },
    {
      "name": "__init__",
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\utils\\__init__.py",
      "docstring": null,
      "classes": [],
      "functions": [],
      "imports": [
        "from file_utils import read_file_safely",
        "from file_utils import create_directory",
        "from file_utils import find_python_files",
        "from json_serializer import serialize_project_data",
        "from json_serializer import save_json_to_file",
        "from json_serializer import load_json_from_file",
        "from json_serializer import format_json_output",
        "from token_counter import estimate_tokens",
        "from token_counter import count_tokens_in_dict"
      ],
      "constants": []
    }
  ],
  "examples": [
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\cli.py",
      "context": "main guard",
      "type": "main_example",
      "code": "if __name__ == \"__main__\":\n    main()",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\cli.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "has_python_files = any((project_path / indicator).exists() for indicator in python_indicators)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\cli.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "has_py_files = any(project_path.glob('**/*.py'))",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\cli.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "config = Config()",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\cli.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "serialized_data = serialize_project_data(project_data)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\cli.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "token_count = estimate_tokens(json.dumps(serialized_data))",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\cli.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "prompt = create_readme_prompt(serialized_data, serialized_data.get('project_metadata', {}).get('name', 'Project'))",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\cli.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "config = Config()",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\cli.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "result = parse_project(str(project_path))",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\cli.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "serialized_data = serialize_project_data(result)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\cli.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "success = save_json_to_file(serialized_data, json_output_path)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\cli.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "api_key = validate_api_requirements(config.model_name, config.api_key)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\cli.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "output_path = Path(args.output)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\cli.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "parser = create_parser()",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\cli.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "config = load_configuration(args)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\cli.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "config.parse_only = getattr(args, 'parse_only', False)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\cli.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "loaded_config = load_config(args.config)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\config.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "budget_sum = sum(self.token_budget_allocation.values())",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\config.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "cache_path = Path(self.cache_dir)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\config.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "config_path = get_default_config_path()",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\config.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "config_path = Path(config_path)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\config.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "config_path = get_default_config_path()",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\config.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "config_path = Path(config_path)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\config.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "config_path = get_default_config_path()",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\config.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "config_path = Path(config_path)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\config.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "config_data = get_config_template()",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\config.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "other_dict = asdict(other)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\__main__.py",
      "context": "main guard",
      "type": "main_example",
      "code": "if __name__ == \"__main__\":\n    # Get the directory containing this file\n    current_dir = Path(__file__).parent\n    # Add parent directory to path so we can import the package\n    sys.path.insert(0, str(current_dir.parent))",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\__main__.py",
      "context": "main guard",
      "type": "main_example",
      "code": "if __name__ == \"__main__\":\n    # Import version info\n    try:\n        from readme_generator import get_version\n    except ImportError:\n        def get_version():\n            return \"0.1.0\"\n    \n    entry_point()",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\dependency_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "seen = set()",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\dependency_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "deps = parse_func(project_path)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\entry_point_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "main_files = list(project_path.glob(\"**/__main__.py\"))",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\entry_point_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "entry_info = _extract_main_module_info(main_file)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\entry_point_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "cli_files = list(project_path.glob(f\"**/{pattern}\"))",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\entry_point_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "setup_entry_points = _extract_setup_entry_points(setup_py)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\entry_point_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "pyproject_entry_points = _extract_pyproject_entry_points(pyproject_toml)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\entry_point_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "entry_info = _extract_cli_script_info(cli_file)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\example_parser.py",
      "context": "comment",
      "type": "comment_example",
      "code": "1. Doctest examples (>>> format)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\example_parser.py",
      "context": "comment",
      "type": "comment_example",
      "code": "3. Example sections",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\example_parser.py",
      "context": "comment",
      "type": "comment_example",
      "code": "Pattern for indented code blocks (following \"Example:\" or similar)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\example_parser.py",
      "context": "comment",
      "type": "comment_example",
      "code": "Look for sections starting with \"Examples:\", \"Example:\", etc.",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\example_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "doctest_examples = _extract_doctest_examples(docstring)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\example_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "code_blocks = _extract_code_blocks(docstring)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\example_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "example_sections = _extract_example_sections(docstring)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\example_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "min_indent = min(len(line) - len(line.lstrip())",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\metadata_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "init_metadata = _parse_init_files(project_path)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\metadata_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "readme_metadata = _parse_readme(project_path)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\metadata_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "init_files = list(project_path.glob(\"**/__init__.py\"))",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\project_parser.py",
      "context": "main guard",
      "type": "main_example",
      "code": "if __name__ == \"__main__\":\n    import sys\n    import json\n    project_root = sys.argv[1] if len(sys.argv) > 1 else \".\"\n    result = parse_project(project_root)\n    print(json.dumps(result, indent=2))",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\project_parser.py",
      "context": "comment",
      "type": "comment_example",
      "code": "Extract examples from this file",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\project_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "metadata = parse_metadata(str(project_path))",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\project_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "dependencies = parse_dependencies(str(project_path))",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\project_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "entry_points = parse_entry_points(str(project_path))",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\project_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "structure = parse_structure(str(project_path))",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\project_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "entry_point_files = set()",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\project_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "total_classes = sum(len(mod.get(\"classes\", [])) for mod in detailed_modules)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\project_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "total_functions = sum(len(mod.get(\"functions\", [])) for mod in detailed_modules)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\project_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "total_methods = sum(",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\project_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "result = parse_project(project_root)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\project_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "code_details = parse_code_file(file_path, extract_full_code=is_entry_point)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\parser\\project_parser.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "file_examples = parse_examples(file_path)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\utils\\content_prioritizer.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "tc = estimate_tokens(str(item))",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\utils\\file_utils.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "root_path = Path(project_path)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\utils\\file_utils.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "p = Path(file_path)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\utils\\json_serializer.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "output_path = Path(file_path)",
      "language": "python"
    },
    {
      "file": "C:\\Users\\lwhitaker\\personal\\SYSC4918\\SYSC4918\\src\\utils\\json_serializer.py",
      "context": "usage pattern",
      "type": "instantiation",
      "code": "json_text = format_json_output(data, indent=indent)",
      "language": "python"
    }
  ],
  "stats": {
    "files_processed": 17,
    "examples_found": 66,
    "classes_found": 3,
    "functions_found": 73,
    "methods_found": 8,
    "entry_points_found": 2
  }
}